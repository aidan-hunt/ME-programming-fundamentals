{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5192cf11",
   "metadata": {},
   "source": [
    "# Practice with NumPy\n",
    "Aidan Hunt, University of Washington\n",
    "\n",
    "***\n",
    "\n",
    "## Learning Objectives\n",
    "After this lesson, students will be able to\n",
    "- Generate NumPy arrays from the contents of files\n",
    "- Traverse NumPy arrays with loops\n",
    "- Visualize the contents of NumPy arrays with matplotlib\n",
    "\n",
    "\n",
    "## Check-in\n",
    "\n",
    "- Homework 3 due Friday (start early!)\n",
    "- Come to office hours or post on discussion board if you have issues\n",
    "- Homework 4 will be posted on Friday (smaller problem plus creative programming)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8d135",
   "metadata": {},
   "source": [
    "## Framing the Problem\n",
    "\n",
    "Today, work an example that will allow us to practice with NumPy and plotting.\n",
    "\n",
    "**Objective:** Post-process and visualize data from an Acoustic Doppler Velocimeter (ADV):\n",
    "- Measures fluid velocity at a point using reflections of acoustic \"pings\"\n",
    "- Measures X, Y, and 2 estimates of Z velocity (Z1 and Z2)\n",
    "\n",
    "**Provided text files:**\n",
    "- `vectrinoData.txt` contains raw data output from the sensor\n",
    "    - First column: Timestamps (s)\n",
    "    - Columns 2-5: Beam velocities (m/s)\n",
    "    - Columns 6-9: Beam amplitudes\n",
    "    - Columns 10-13: Beam correlation as integer between 0 and 255 (255 = perfect correlation)\n",
    "- `vectrinoTransform.txt` contains a 4x4 coordinate transformation matrix for transforming from beam coordinates to XYZ coordinates\n",
    "\n",
    "**Post processing pipeline:**\n",
    "- Import data\n",
    "- Filter readings with correlations below a certain % threshold\n",
    "- Convert beam velocities to XYZ\n",
    "- Plot filtered and unfiltered velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92785a",
   "metadata": {},
   "source": [
    "***\n",
    "## 1) Pseudocode\n",
    "\n",
    "Our pseudocode is essentially the post processing pipeline!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataFile = 'vectrinoData.txt'\n",
    "coordFile = 'vectrinoTransform.txt'\n",
    "\n",
    "# Import data\n",
    "    # Read from txt file using numpy?\n",
    "\n",
    "# Clean data\n",
    "    # Identify \"bad readings\" based on correlation threshold\n",
    "    # Interpolate other these readings using linear interpolation\n",
    "\n",
    "# Transform data to XYZ coordinates\n",
    "    # Use transformation matrix for this\n",
    "\n",
    "# Plot\n",
    "    # Need both filtered and raw velocities\n",
    "    # Select beam to plot\n",
    "    # will need a plotting package for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9838ba31",
   "metadata": {},
   "source": [
    "***\n",
    "## 2) Write function for importing the data\n",
    "\n",
    "NumPy provides a handy function for importing simple text data: `numpy.loadtxt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(np.loadtxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3e6d2",
   "metadata": {},
   "source": [
    "Let's use this to import the data. Since this is a distinct task, define a function:\n",
    "- (Note, we need to specify the delimiter or else we get an error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(dataFile):\n",
    "    '''\n",
    "    Given a Vectrino data file, extracts and returns timestamps, beam\n",
    "    velocities, and beam correlations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataFile : str\n",
    "        Name of the Vectrino .txt file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timeStamps : numpy array of floats\n",
    "        Timestamp for each sample, in seconds.\n",
    "    beamVels : numpy array of floats\n",
    "        nx4 array of velocity readings, in m/s. Rows represent samples, \n",
    "        columns represent each beam.\n",
    "    beamCorr : numpy array of floats\n",
    "        nx4 array of beam correlations, in %. Rows represent samples, columns \n",
    "        represent each beam.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Import full data matrix\n",
    "    allData = np.loadtxt(dataFile, delimiter=',')\n",
    "    \n",
    "    # Extract quantities of interest\n",
    "    timeStamps = allData[:,0]\n",
    "    beamVels = allData[:,1:5]\n",
    "    beamCorr = allData[:,9:] / 255 * 100\n",
    "    \n",
    "    return timeStamps, beamVels, beamCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStamps, beamVels, beamCorr = importData('vectrinoData.txt')\n",
    "\n",
    "print(beamVels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b341b",
   "metadata": {},
   "source": [
    "***\n",
    "## 3) Write function for cleaning velocity\n",
    "\n",
    "Let's think about this a bit more (draw on board):\n",
    "- We want to throw out all readings for a given sample if the correlation on any beam is less than a threshold\n",
    "- For each beam, we want to replace those readings with linear interpolation based on the surrounding \"good\" points\n",
    "\n",
    "**Take 1 min to pseudocode this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec6677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanVelocity(timeStamps, beamVels, beamCorr):\n",
    "    # Identify correlations below a particular threshold\n",
    "        # Convert from elementwise true/false to row-wise true/false\n",
    "    \n",
    "    \n",
    "    # For each beam\n",
    "        # Identify \"good\" points to use as our interpolation basis\n",
    "        # Generate \"clean\" time series using interpolation\n",
    "        \n",
    "    # Return the cleaned velocity vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f8d8a",
   "metadata": {},
   "source": [
    "Code it up:\n",
    "- Use `np.any` to consider entire rows as \"bad\" if one element is \"bad\".\n",
    "- Use `np.interp`to perform interpolation.\n",
    "- Add threshold as optional parameter because maybe we want to change it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanVelocity(timeStamps, beamVel, beamCorr, corrThresh=75):\n",
    "    '''\n",
    "    Given Vectrino time stamps, beam velocities, beam correlations, removes\n",
    "    readings where the correlation on any beam is below a specified threshold,\n",
    "    and replaces them via linear interpolation of the surrounding points.\n",
    "    The cleaned velocities are returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timeStamps : numpy array of floats\n",
    "        Timestamp for each sample, in seconds.\n",
    "    beamVels : numpy array of floats\n",
    "        nx4 array of velocity readings, in m/s. Rows represent samples, \n",
    "        columns represent each beam.\n",
    "    beamCorr : numpy array of floats\n",
    "        nx4 array of beam correlations, in %. Rows represent samples, columns \n",
    "        represent each beam.\n",
    "    corrThresh : float, optional\n",
    "        Threshold (as a percentage) at and below which readings are replaced via linear\n",
    "        interpolation. The default is 75.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cleanVel : numpy array of floats\n",
    "        nx4 array of velocity readings with \"bad\" readings replaced, in m/s. \n",
    "        Rows represent samples, columns represent each beam. \n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Identify \"bad\" readings\n",
    "    badReading = beamCorr <= corrThresh\n",
    "    badRows = np.any(badReading, axis=1) # If an element of a row is false, the whole row is false\n",
    "    \n",
    "    # Preallocate matrix for filtered readings\n",
    "    cleanVel = np.zeros(beamVel.shape)\n",
    "    nBeams = beamVel.shape[-1]\n",
    "    \n",
    "    for i in range(nBeams): # For each beam of the Vectrino\n",
    "        # Pull out \"good\" points to base interpolation on\n",
    "        goodTime = timeStamps[~badRows]\n",
    "        goodVel = beamVel[~badRows, i]\n",
    "        \n",
    "        # Interpolate all time stamps with good time stamps as basis\n",
    "        cleanVel[:,i] = np.interp(timeStamps, goodTime, goodVel)\n",
    "        \n",
    "    return cleanVel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d86599",
   "metadata": {},
   "outputs": [],
   "source": [
    "beamVel = cleanVelocity(timeStamps, beamVels, beamCorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc21b06",
   "metadata": {},
   "source": [
    "***\n",
    "## 4) Write a function for performing the coordinate transformation\n",
    "\n",
    "First, we need to import the transformation matrix (use `np.loadtxt` again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "tMat = np.loadtxt('vectrinoTransform.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eef3bc",
   "metadata": {},
   "source": [
    "Now perform the transformation.\n",
    "- Coordinate transformation -> matrix product\n",
    "- Transformation matrix usually operates on column vector (where rows are unique dimenisons).\n",
    "- But here, the columns are unique dimensions\n",
    "\n",
    "So how do we apply it?\n",
    "- Use `@` operator to perform matrix multiplication\n",
    "- Transpose beam velocities to match convention we are used to for rotation matrices\n",
    "- Transpose back so that matrix is shaped how we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinateTransform(beamVels, tMat):\n",
    "    '''\n",
    "    Converts velocities in beam coordinates to velocities in xyz coordinates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    beamVels : numpy array of floats\n",
    "        nx4 array of velocity readings in beam coordinates. Rows represent\n",
    "        samples, columns represent each beam.\n",
    "    tMat : numpy array of floats\n",
    "       Coordinate transformation matrix for beam to xyz, as a 4x4 matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array of floats\n",
    "        nx4 array of velocity readings in xyz coordinates. Rows represent\n",
    "        samples, columns represent each beam (X, Y, Z1, Z2).\n",
    "\n",
    "    '''\n",
    "    xyzVels = tMat @ beamVels.T\n",
    "    return xyzVels.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83133d7",
   "metadata": {},
   "source": [
    "***\n",
    "## 5) Put it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define data files\n",
    "dataFile = 'vectrinoData.txt'\n",
    "transformFile = 'vectrinoTransform.txt'\n",
    "\n",
    "# Import data from these files\n",
    "time, beamVel, beamCorr = importData(dataFile)\n",
    "\n",
    "# Clean velocity time series based on correlation values\n",
    "beamFilt = cleanVelocity(time, beamVel, beamCorr, corrThresh=95)\n",
    "\n",
    "# Import transformation matrix and apply coordinate transformation\n",
    "tMat = np.loadtxt(transformFile, delimiter=',')\n",
    "vel = coordinateTransform(beamVel, tMat)\n",
    "velFilt = coordinateTransform(beamFilt, tMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd999be",
   "metadata": {},
   "source": [
    "## 6) Plot using `matplotlib`\n",
    "\n",
    "Plotting package provides simple plotting interface (we'll do a deep dive later in the quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7fc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotVelocity(time, vel, velFilt, coordInd):\n",
    "    '''\n",
    "    Plots a time series of the measured velocity (both filtered and unfiltered)\n",
    "    in the given coorindate direction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time : numpy vector of floats\n",
    "        Time stamps of each velocity reading, in seconds\n",
    "    vel : numpy array of floats\n",
    "        nx4 array of raw velocity readings in beam coordinates. Rows represent\n",
    "        samples, columns represent each beam.\n",
    "    velFilt : numpy array of floats\n",
    "        nx4 array of filtered velocity readings in beam coordinates. Rows represent\n",
    "        samples, columns represent each beam.\n",
    "    coordInd : int\n",
    "        Integer that represents which coordinate direction to plot:\n",
    "            0 = X\n",
    "            1 = Y\n",
    "            2 = Z1\n",
    "            3 = Z2\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # Generate plot of velocity in given coordinate direction\n",
    "    plt.figure()\n",
    "    plt.plot(time, vel[:,coordInd])\n",
    "    plt.plot(time, velFilt[:,coordInd])\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Velocity [m/s]')\n",
    "    plt.legend(['Unfiltered', 'Filtered'])\n",
    "    \n",
    "    # Generate text for title based on coordinate index\n",
    "    coords = ['X', 'Y', 'Z1', 'Z2']\n",
    "    plt.title('Velocity in ' + coords[coordInd] + ' direction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f0d23",
   "metadata": {},
   "source": [
    "## 8) Compare the results with data cleaning to those without"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc3513",
   "metadata": {},
   "source": [
    "Adjust correlation threshold parameter to change how much filtering is imposed on the velocity readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c80870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define data files\n",
    "dataFile = 'vectrinoData.txt'\n",
    "transformFile = 'vectrinoTransform.txt'\n",
    "\n",
    "# Import data from these files\n",
    "time, beamVel, beamCorr = importData(dataFile)\n",
    "\n",
    "# Clean velocity time series based on correlation values\n",
    "beamFilt = cleanVelocity(time, beamVel, beamCorr, corrThresh=95)\n",
    "\n",
    "# Import transformation matrix and apply coordinate transformation\n",
    "tMat = np.loadtxt(transformFile, delimiter=',')\n",
    "vel = coordinateTransform(beamVel, tMat)\n",
    "velFilt = coordinateTransform(beamFilt, tMat)\n",
    "\n",
    "# Plot the velocity in a given direction\n",
    "beamInd = 0\n",
    "plotVelocity(time, vel, velFilt, beamInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25208fd4",
   "metadata": {},
   "source": [
    "**What if we wanted to use this for several data files?**\n",
    "Define a function that performs all of the processing (and, if you want, produces a plot), given a data file as an input.\n",
    "Then pass in each file using a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc81b4",
   "metadata": {},
   "source": [
    "***\n",
    "## Other packages use NumPy!\n",
    "\n",
    "Many other packages build upon the scientific computing foundation provided by NumPy:\n",
    "\n",
    "### __[Matplotlib](https://matplotlib.org/stable/index.html#)__\n",
    "- Popular plotting package\n",
    "- MATLAB-like plotting functionality\n",
    "\n",
    "To import and use Matplotlib, typically import `matplotlib.pyplot`: the interface that gives us useful scripting commands\n",
    "\n",
    "### __[SciPy](https://scipy.org/)__\n",
    "- \"Scientific Python\"\n",
    "- Many useful numerical routines\n",
    "    - Numerical integration (trapezoidal method, ODE solvers)\n",
    "    - Root-finding\n",
    "    - Optimization\n",
    "    \n",
    "### __[Scikit-learn](https://scikit-learn.org/stable/index.html)__\n",
    "- Popular machine learning package\n",
    "- Built on NumPy and SciPy\n",
    "\n",
    "### __[Pandas](https://pandas.pydata.org/)__\n",
    "- Useful package for working with tabular data (i.e., spreadsheets)\n",
    "- More on this next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc3498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
